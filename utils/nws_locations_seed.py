import requests
import csv
from io import StringIO

# Get USGS sites from API
# url = "http://localhost/usgs/sites"
# r = requests.get(url)
# sites = r.json()

# usgs_sites = []
# for site in sites:
#     usgs_sites.append(site["site_number"])

# Get Existing stages from API
# url = "http://localhost/nws/stages"
# r = requests.get(url)
# stages = r.json()

# existing_stages = {}
# for site_stages in stages:
#     existing_stages[site_stages["nwsid"]] = site_stages


# Get states from API
url = "http://localhost/states"
r = requests.get(url)
api_states = r.json()

states = []
for state in api_states:
    states.append(state["abbreviation"])


url = "https://water.weather.gov/monitor/ahpsreport.php?type=csv"
# print(url)
r = requests.get(url)
# print(r.text)
buff = StringIO(r.text)
reader = csv.reader(buff, delimiter=",")

keys = []
result = []

for idx, line in enumerate(reader):
    if idx == 0:
        # this is the header
        keys = line
        # print(keys)
    else:
        # Build each line (object) by setting the keys and values
        _line = {}
        for i, k in enumerate(keys):
            _line[k] = line[i].strip()
        result.append(_line)

# for line in result:
#         print('-'*10)
#         for k,v in line.items():
#             print(k, '=>', v)

loc_sql = """
DO $$

DECLARE 
    -- this file was generated by python script
    nws_site_datasource_id uuid;

BEGIN

SELECT d.id into nws_site_datasource_id
FROM datasource d 
JOIN datatype dt ON dt.id = d.datatype_id 
JOIN provider p ON p.id = d.provider_id 
WHERE dt.slug = 'nws-site' AND p.slug = 'noaa-nws';\n\n
"""

nws_site_sql = ""

# for state in states:
for state in ["CA", "FL", "OH", "TN", "MN", "WV"]:
    last_line = len(result)
    loc_sql += f"\n-- {state} NWS Locations"
    loc_sql += "\nINSERT INTO location (datasource_id, slug, code, geometry, state_id, attributes) VALUES\n"

    # nws_site_sql += f"\n-- {state} NWS Sites"
    # nws_site_sql += "\nINSERT INTO nws_site (location_id, name, nws_li) VALUES\n"

    for idx, line in enumerate(result):

        if line["state"].strip() == state.lower():

            # Entry must have:
            # 1) NWSID = 5 chars
            # 2) a proper USGS ID
            # 3) stage must have a unit of 'FT
            # 4) all stages cannot be 0

            if (
                len(line["nws shef id"].strip()) == 5
                and line["usgs id"].strip() != ""
                and line["in service"] == "Yes"
            ):

                if line["proximity"].strip() in ["at", "near", "below", "near"]:
                    # ex: Name above xyz lake
                    name = f"{line['location name'].strip()} {line['proximity'].strip()} {line['river/water-body name'].strip()}"
                else:
                    name = line["location name"].strip()

                nws_li = line["nws shef id"].strip()
                state = line["state"].strip().lower()

                latitude = (
                    float(line["latitude"].strip().lower())
                    if line["latitude"].strip() != ""
                    else 0
                )
                longitude = (
                    -1 * abs(float(line["longitude"].strip().lower()))
                    if line["latitude"].strip() != ""
                    else 0
                )

                loc_sql += f"""(nws_site_datasource_id, '{nws_li.lower()}', '{nws_li.lower()}', ST_GeomFromText('POINT({longitude} {latitude})',4326), (SELECT gid from tiger_data.state_all where lower(stusps) = '{state.lower()}'), '{{"name":"{name}"}}'),\n"""

                # nws_site_sql += f"((SELECT id from location where slug = '{nws_li}'), '{name}', '{nws_li}'),\n"

    # semi-colon on last line
    loc_sql = loc_sql[0:-2] + ";"
    # nws_site_sql = nws_site_sql[0:-2] + ";"

    # last_state = state

print(loc_sql)
# print(nws_site_sql)

print("\n\nEND$$;")
